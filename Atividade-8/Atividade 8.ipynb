{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f24d55a8",
   "metadata": {},
   "source": [
    "# Atividade 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab59b8",
   "metadata": {},
   "source": [
    "Nessa atividade vocês irão trabalhar em um problema de classificação de texto multiclasse. Considere o conjunto de dados sobre fetch_20newsgroups  \n",
    "\n",
    "    \"The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of our knowledge, it was originally collected by Ken Lang, probably for his paper “Newsweeder: Learning to filter netnews,” though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\"\n",
    "    \n",
    "Dado esse contexto, escolha um único classificador, sem otimizar hiperparametros, treine e teste modelos considerando\n",
    "\n",
    "    Bag of Words (contagem), sem pré-processamento\n",
    "    TF-IDF, sem pré-processamento \n",
    "    Bag of Words, com pré-processamento\n",
    "    TF-IDF, com pré-processamento\n",
    "    \n",
    "Considere a métrica da acurácia e compare os resultados em uma tabela.\n",
    "\n",
    "As etapas de pré-processamento devem conter pelo menos:\n",
    "\n",
    "    lowercase\n",
    "    remoção de pontuação\n",
    "    remoção de números \n",
    "    remoção de stopwords (dica: utilize a biblioteca NLTK)\n",
    "    lematização ou stemming (apenas um dos dois)\n",
    "    \n",
    "Outras etapas que você julgar necessárias podem ser utilizadas. Crie uma função para cada etapa e uma função chamada preprocess() que chame todas as etapas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "247ac691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "95e1f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test',  shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "029425b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bf093c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = twenty_train.data\n",
    "y_train = twenty_train.target\n",
    "data_test = twenty_test.data\n",
    "y_test = twenty_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51496054",
   "metadata": {},
   "source": [
    "### Bag of Words (sem pré-processamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5ff0e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bw = CountVectorizer()\n",
    "X_train_bw = bw.fit_transform(data_train)\n",
    "X_test_bw = bw.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2737abf2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00\n",
      "000\n",
      "0000\n",
      "00000\n",
      "000000\n",
      "00000000\n",
      "0000000004\n",
      "0000000005\n",
      "00000000b\n",
      "00000001\n",
      "00000001b\n",
      "0000000667\n",
      "00000010\n",
      "00000010b\n",
      "00000011\n",
      "00000011b\n",
      "0000001200\n",
      "00000074\n",
      "00000093\n",
      "000000e5\n",
      "00000100\n",
      "00000100b\n",
      "00000101\n",
      "00000101b\n",
      "00000110\n",
      "00000110b\n",
      "00000111\n",
      "00000111b\n",
      "00000315\n",
      "000005102000\n",
      "00000510200001\n",
      "000007\n",
      "00000ee5\n",
      "00001000\n",
      "00001000b\n",
      "00001001\n",
      "00001001b\n",
      "00001010\n",
      "00001010b\n",
      "00001011\n",
      "00001011b\n",
      "000010af\n",
      "00001100\n",
      "00001100b\n",
      "00001101\n",
      "00001101b\n",
      "00001110\n",
      "00001110b\n",
      "00001111\n",
      "00001111b\n",
      "000021\n",
      "000042\n",
      "000062david42\n",
      "000094\n",
      "0000vec\n",
      "0001\n",
      "00010000\n",
      "00010000b\n",
      "00010001\n",
      "00010001b\n",
      "00010010\n",
      "00010010b\n",
      "00010011\n",
      "00010011b\n",
      "000100255pixel\n",
      "00010100\n",
      "00010100b\n",
      "00010101\n",
      "00010101b\n",
      "00010110\n",
      "00010110b\n",
      "00010111\n",
      "00010111b\n",
      "00011000\n",
      "00011000b\n",
      "00011001\n",
      "00011001b\n",
      "00011010\n",
      "00011010b\n",
      "00011011\n",
      "00011011b\n",
      "00011100\n",
      "00011100b\n",
      "00011101\n",
      "00011101b\n",
      "00011110\n",
      "00011110b\n",
      "00011111\n",
      "00011111b\n",
      "00014\n",
      "000152\n",
      "0001mpc\n",
      "0001x7c\n",
      "0002\n",
      "000246\n",
      "000256\n",
      "0003\n",
      "000359\n",
      "0004\n",
      "000406\n"
     ]
    }
   ],
   "source": [
    "# printando os dados do conjunto para analisar quais etapas de pré-processamento são necessárias, e para comparação com os dados pós pré-processamento..\n",
    "# print(bw.get_feature_names())\n",
    "c=0\n",
    "for i in bw.get_feature_names():\n",
    "    print(i)\n",
    "    c+=1\n",
    "    if c == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a4aca2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bw_shape = X_train_bw.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "32c951a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_bw, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "55676c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "93b24c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia foi de: 77.28%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "A1 = accuracy_score(y_test, y_predict)\n",
    "print(f'A acurácia foi de: {round(A1*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae4677",
   "metadata": {},
   "source": [
    "### TF-IDF (sem pré-processamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "acc5f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer()\n",
    "X_train_tf = tf.fit_transform(data_train)\n",
    "X_test_tf = tf.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9c8cfb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_shape = X_train_bw.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "879a9f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "309dbf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a96e870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia foi de: 77.39%\n"
     ]
    }
   ],
   "source": [
    "A2 = accuracy_score(y_test, y_predict)\n",
    "print(f'A acurácia foi de: {round(A2*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b5c911",
   "metadata": {},
   "source": [
    "### Etapas de pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "72ec0b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "42a2ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_pontuacao(text):\n",
    "    sem_pontuacao=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return sem_pontuacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "762dbf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(text):\n",
    "    return text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "48b78f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def remove_stop_words(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    texto = [w for w in text.split() if w not in stopwords]\n",
    "    frase = \" \".join(texto)\n",
    "    return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8c4b6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_nums(text):\n",
    "    num_regex = '\\d+'\n",
    "    t = re.sub(num_regex, '', text)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1ff066c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    texto = [wordnet_lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    frase = \" \".join(texto)\n",
    "    return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "544e1429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "        N = remove_nums(text)\n",
    "        L = lower(N)\n",
    "        P = remover_pontuacao(L)\n",
    "        R = remove_stop_words(P)\n",
    "        lem = lemmatizer(R)\n",
    "        return lem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8b050",
   "metadata": {},
   "source": [
    "### Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b8e95808",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_PP = []\n",
    "for i in range(len(data_train)):\n",
    "    F = preprocess(data_train[i])\n",
    "    X_train_PP.append(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0be694de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_PP = []\n",
    "for i in range(len(data_test)):\n",
    "    F = preprocess(data_test[i])\n",
    "    X_test_PP.append(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a4351",
   "metadata": {},
   "source": [
    "#### Comparação de um texto antes e depois do pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "200596b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a5386f11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lerxstwamumdedu wheres thing subject car nntppostinghost racwamumdedu organization university maryland college park line wondering anyone could enlighten car saw day door sport car looked late early called bricklin door really small addition front bumper separate rest body know anyone tellme model name engine spec year production car made history whatever info funky looking car please email thanks il brought neighborhood lerxst'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_PP[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aad1c8d",
   "metadata": {},
   "source": [
    "### Bag of Words (com pré-processamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0280bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = CountVectorizer()\n",
    "X_train_PP_bw = bw.fit_transform(X_train_PP)\n",
    "X_test_PP_bw = bw.transform(X_test_PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a6745d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_PP_bw_shape = X_train_PP_bw.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "28316750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa\n",
      "aaa\n",
      "aaaa\n",
      "aaaaaaaaaaaa\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg\n",
      "aaaaagggghhhh\n",
      "aaah\n",
      "aaahh\n",
      "aaahhhh\n",
      "aaai\n",
      "aaaimit\n",
      "aaalexlcsmitedu\n",
      "aaamajors\n",
      "aab\n",
      "aabcichlidcom\n",
      "aabluearbortextcom\n",
      "aacalcomsocalcom\n",
      "aacc\n",
      "aachen\n",
      "aaclevelandfreenetedu\n",
      "aacrnsuinpfr\n",
      "aadams\n",
      "aadangermousemitreorg\n",
      "aadnsi\n",
      "aadscrsiemenscom\n",
      "aaexpolcsmitedu\n",
      "aafcsymasussexacuk\n",
      "aafdcbedcbceb\n",
      "aaffff\n",
      "aafffff\n",
      "aafnscclehighedu\n",
      "aafnzfidonetorg\n",
      "aafreenetcarleton\n",
      "aafreenetcarletonca\n",
      "aagrendalcorpsuncom\n",
      "aagumbyaltoscom\n",
      "aah\n",
      "aaigcapcorg\n",
      "aainetgwpadeccom\n",
      "aainsaneapanaorgau\n",
      "aajscnasagov\n",
      "aakeplerunhedu\n",
      "aalborg\n",
      "aaldoubocopperdenvercoloradoedu\n",
      "aalmchgurmeyaridiylpehpaifhnfmqqlchvcduajjebndih\n",
      "aalocutuscscoloradoedu\n",
      "aalternate\n",
      "aamazing\n",
      "aamir\n",
      "aammmaaaazzzzzziinnnnggggg\n",
      "aamothrasyredu\n",
      "aams\n",
      "aamydualuucp\n",
      "aan\n",
      "aanbieden\n",
      "aanekocssgov\n",
      "aanerud\n",
      "aangeboden\n",
      "aangegeven\n",
      "aangezien\n",
      "aantal\n",
      "aantalsnijpunten\n",
      "aantepnteptmgneccojp\n",
      "aao\n",
      "aap\n",
      "aaph\n",
      "aapizzaboxdemoncouk\n",
      "aapjj\n",
      "aaplayexe\n",
      "aapp\n",
      "aardvarkcygnuslalocuscom\n",
      "aardvarkspicalalocuscom\n",
      "aarebelsbbingrcom\n",
      "aargh\n",
      "aarghhhh\n",
      "aarhus\n",
      "aario\n",
      "aarm\n",
      "aaron\n",
      "aaronbinahccbrandeisedu\n",
      "aaronbratcherfpmmacuchicagoedu\n",
      "aaronbratcherfpmuchicagoedu\n",
      "aaroncathenamitedu\n",
      "aaronson\n",
      "aarp\n",
      "aarseth\n",
      "aarskog\n",
      "aartolsen\n",
      "aarvikismenntis\n",
      "aasaiaa\n",
      "aaseastarseashell\n",
      "aasked\n",
      "aasparcjadecom\n",
      "aaspocwruedu\n",
      "aassists\n",
      "aasunestackenkthse\n",
      "aasunpanixcom\n",
      "aatchoo\n",
      "aatherosepdxcom\n",
      "aausmausmaedu\n"
     ]
    }
   ],
   "source": [
    "# print(bw.get_feature_names())\n",
    "c=0\n",
    "for i in bw.get_feature_names():\n",
    "    print(i)\n",
    "    c+=1\n",
    "    if c == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cf1365c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_PP_bw, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2a96d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test_PP_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "829b768e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia foi de: 81.24%\n"
     ]
    }
   ],
   "source": [
    "A3 = accuracy_score(y_test, y_predict)\n",
    "print(f'A acurácia foi de: {round(A3*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a500ae",
   "metadata": {},
   "source": [
    "### TF-IDF (com pré-processamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8b6be62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()\n",
    "X_train_PP_tf = tf.fit_transform(X_train_PP)\n",
    "X_test_PP_tf = tf.transform(X_test_PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "97762334",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_PP_tf_shape = X_train_PP_tf.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "be420deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_PP_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "532e5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test_PP_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "636cc29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia foi de: 81.43%\n"
     ]
    }
   ],
   "source": [
    "A4 = accuracy_score(y_test, y_predict)\n",
    "print(f'A acurácia foi de: {round(A4*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e1a17",
   "metadata": {},
   "source": [
    "## Teste de pré-processamento para retirar palavras sem sentido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43db69b",
   "metadata": {},
   "source": [
    "### Bag of Words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "50caa6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizando min_df para ignorar palavras que se repetem em menos que dois documentos.\n",
    "bw2 = CountVectorizer(min_df=2)\n",
    "X_train_PP_bw2 = bw2.fit_transform(X_train_PP)\n",
    "X_test_PP_bw2 = bw2.transform(X_test_PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fd7ca5f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa\n",
      "aaa\n",
      "aaah\n",
      "aacalcomsocalcom\n",
      "aadangermousemitreorg\n",
      "aaffff\n",
      "aafreenetcarleton\n",
      "aafreenetcarletonca\n",
      "aainetgwpadeccom\n",
      "aainsaneapanaorgau\n",
      "aaldoubocopperdenvercoloradoedu\n",
      "aamir\n",
      "aammmaaaazzzzzziinnnnggggg\n",
      "aapizzaboxdemoncouk\n",
      "aardvarkcygnuslalocuscom\n",
      "aardvarkspicalalocuscom\n",
      "aargh\n",
      "aarghhhh\n",
      "aarhus\n",
      "aario\n",
      "aaron\n",
      "aaronbinahccbrandeisedu\n",
      "aaronbratcherfpmuchicagoedu\n",
      "aaroncathenamitedu\n",
      "aasparcjadecom\n",
      "aaspocwruedu\n",
      "aatchoo\n",
      "aauwpiugyvnnlftpnnlcmscpjupykviabrgihcmmgvghpymfbhqg\n",
      "ab\n",
      "ababspalestinians\n",
      "abad\n",
      "abandon\n",
      "abandoned\n",
      "abandoning\n",
      "abandonment\n",
      "abate\n",
      "abates\n",
      "abberation\n",
      "abbey\n",
      "abbot\n",
      "abbott\n",
      "abbreviation\n",
      "abc\n",
      "abcdefghijklmnopqrstuvwxyz\n",
      "abclevelandfreenetedu\n",
      "abd\n",
      "abdel\n",
      "abdkwstdvax\n",
      "abdomen\n",
      "abdominal\n",
      "abduction\n",
      "abdul\n",
      "abdullah\n",
      "abel\n",
      "aben\n",
      "aberacuk\n",
      "aberdeen\n",
      "aberrant\n",
      "aberration\n",
      "aberystwyth\n",
      "abetter\n",
      "abfreenetcarletonca\n",
      "abg\n",
      "abhin\n",
      "abhor\n",
      "abhorent\n",
      "abhorrent\n",
      "abide\n",
      "abiding\n",
      "ability\n",
      "abiogenesis\n",
      "ablarcnasagov\n",
      "ablaze\n",
      "able\n",
      "ablebodied\n",
      "ablemktcomcom\n",
      "ably\n",
      "abner\n",
      "abnormal\n",
      "abnormality\n",
      "abnovaccpurdueedu\n",
      "abo\n",
      "aboard\n",
      "abode\n",
      "abolish\n",
      "abolished\n",
      "abolishing\n",
      "abolishment\n",
      "abolition\n",
      "abolitionist\n",
      "abomb\n",
      "abominable\n",
      "abomination\n",
      "abort\n",
      "aborted\n",
      "abortion\n",
      "abortionlaw\n",
      "abott\n",
      "abotu\n",
      "abou\n"
     ]
    }
   ],
   "source": [
    "# print(bw2.get_feature_names())\n",
    "c=0\n",
    "for i in bw2.get_feature_names():\n",
    "    print(i)\n",
    "    c+=1\n",
    "    if c == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "809f4d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_PP_bw2_shape = X_train_PP_bw2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e45036ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = MultinomialNB()\n",
    "clf2.fit(X_train_PP_bw2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5d4dc8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf2.predict(X_test_PP_bw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "655c2c87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia foi de: 82.86%\n"
     ]
    }
   ],
   "source": [
    "# Apresentou pequena melhora na acurácia, porém, o texto continuou com muitas palavras sem sentido.\n",
    "A5 = accuracy_score(y_test, y_predict)\n",
    "print(f'A acurácia foi de: {round(A5*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8da1fed",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4d12825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf2 = TfidfVectorizer(min_df=2)\n",
    "X_train_PP_tf2 = tf2.fit_transform(X_train_PP)\n",
    "X_test_PP_tf2 = tf2.transform(X_test_PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8cda19a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_PP_tf2_shape = X_train_PP_tf2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4788a2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = MultinomialNB()\n",
    "clf3.fit(X_train_PP_tf2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e7faa1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf3.predict(X_test_PP_tf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1796c03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia foi de: 81.94%\n"
     ]
    }
   ],
   "source": [
    "A6 = accuracy_score(y_test, y_predict)\n",
    "print(f'A acurácia foi de: {round(A6*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc11d001",
   "metadata": {},
   "source": [
    "### Bag of Words 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5e037a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando min_df para ignorar palavras que se repetem em menos que 1% dos documentos.\n",
    "bw3 = CountVectorizer(min_df=0.01)\n",
    "X_train_PP_bw3 = bw3.fit_transform(X_train_PP)\n",
    "X_test_PP_bw3 = bw3.transform(X_test_PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "15219ce3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ability\n",
      "able\n",
      "absolute\n",
      "absolutely\n",
      "academic\n",
      "accept\n",
      "acceptable\n",
      "accepted\n",
      "access\n",
      "accident\n",
      "according\n",
      "account\n",
      "accurate\n",
      "across\n",
      "act\n",
      "action\n",
      "active\n",
      "activity\n",
      "actual\n",
      "actually\n",
      "ad\n",
      "adam\n",
      "add\n",
      "added\n",
      "addition\n",
      "additional\n",
      "address\n",
      "administration\n",
      "admit\n",
      "advance\n",
      "advanced\n",
      "advantage\n",
      "advice\n",
      "afraid\n",
      "age\n",
      "agency\n",
      "agent\n",
      "ago\n",
      "agree\n",
      "ahead\n",
      "aid\n",
      "air\n",
      "al\n",
      "alan\n",
      "algorithm\n",
      "alive\n",
      "allen\n",
      "allow\n",
      "allowed\n",
      "allows\n",
      "almost\n",
      "alone\n",
      "along\n",
      "already\n",
      "also\n",
      "alternative\n",
      "although\n",
      "always\n",
      "amendment\n",
      "america\n",
      "american\n",
      "among\n",
      "amount\n",
      "analysis\n",
      "ancient\n",
      "andor\n",
      "andrew\n",
      "andy\n",
      "angeles\n",
      "animal\n",
      "announcement\n",
      "anonymous\n",
      "another\n",
      "answer\n",
      "anybody\n",
      "anymore\n",
      "anyone\n",
      "anything\n",
      "anyway\n",
      "anywhere\n",
      "apart\n",
      "apparently\n",
      "appear\n",
      "appears\n",
      "apple\n",
      "application\n",
      "applied\n",
      "apply\n",
      "appreciate\n",
      "appreciated\n",
      "approach\n",
      "appropriate\n",
      "apr\n",
      "aprathosrutgersedu\n",
      "april\n",
      "arab\n",
      "archive\n",
      "area\n",
      "arent\n",
      "argue\n"
     ]
    }
   ],
   "source": [
    "# print(bw3.get_feature_names())\n",
    "c=0\n",
    "for i in bw3.get_feature_names():\n",
    "    print(i)\n",
    "    c+=1\n",
    "    if c == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3ec3aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_PP_bw3_shape = X_train_PP_bw3.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cf792123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = MultinomialNB()\n",
    "clf3.fit(X_train_PP_bw3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8579241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf3.predict(X_test_PP_bw3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7eb115eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia foi de: 70.14%\n"
     ]
    }
   ],
   "source": [
    "# Conseguiu retirar todas as palavras sem sentido, porém, causou um grande prejuízo na acurácia.\n",
    "A7 = accuracy_score(y_test, y_predict)\n",
    "print(f'A acurácia foi de: {round(A7*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40eb6bd",
   "metadata": {},
   "source": [
    "## Tabela de comparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4b38b55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelos</th>\n",
       "      <th>Accuracy(%)</th>\n",
       "      <th>Dimensões</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BoW(SP)</td>\n",
       "      <td>77.28</td>\n",
       "      <td>130107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF(SP)</td>\n",
       "      <td>77.39</td>\n",
       "      <td>130107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BoW(PP)</td>\n",
       "      <td>81.24</td>\n",
       "      <td>111379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TF-IDF(PP)</td>\n",
       "      <td>81.43</td>\n",
       "      <td>111379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BoW(PP2)</td>\n",
       "      <td>82.86</td>\n",
       "      <td>45567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TF-IDF(PP2)</td>\n",
       "      <td>81.94</td>\n",
       "      <td>45567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BoW(PP3)</td>\n",
       "      <td>70.14</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Modelos  Accuracy(%)  Dimensões\n",
       "0      BoW(SP)        77.28     130107\n",
       "1   TF-IDF(SP)        77.39     130107\n",
       "2      BoW(PP)        81.24     111379\n",
       "3   TF-IDF(PP)        81.43     111379\n",
       "4     BoW(PP2)        82.86      45567\n",
       "5  TF-IDF(PP2)        81.94      45567\n",
       "6     BoW(PP3)        70.14       1796"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Modelos': ['BoW(SP)', 'TF-IDF(SP)', 'BoW(PP)', 'TF-IDF(PP)', 'BoW(PP2)', 'TF-IDF(PP2)', 'BoW(PP3)'],\n",
    "        'Accuracy(%)': [round(A1*100, 2), round(A2*100, 2), round(A3*100, 2), round(A4*100, 2), round(A5*100, 2),round(A6*100, 2), round(A7*100, 2)],\n",
    "        'Dimensões':[X_train_bw_shape, X_train_tf_shape, X_train_PP_bw_shape, X_train_PP_tf_shape, X_train_PP_bw2_shape, X_train_PP_tf2_shape, X_train_PP_bw3_shape],\n",
    "        }\n",
    "tabela = pd.DataFrame(data)\n",
    "tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5665b706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
